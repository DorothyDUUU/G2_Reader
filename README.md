![logo](asset/logo.png)

# ğŸ’» $G^2$â€‘Reader: Dynamic DAGâ€‘based Document Reader for Multiâ€‘modal Longâ€‘Document Understanding

[![project](https://img.shields.io/badge/project-Page-blue)](#)
[![arXiv](https://img.shields.io/badge/arXiv-25xx.xxxxx-b31b1b.svg)](#)
[![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)](LICENSE)
=======

> ğŸ¯ **$G^2$â€‘Reader** is a dual-graph RAG framework designed for complex multimodal document QA. It overcomes "semantic fragmentation" by utilizing a Content Graph ($\mathcal{G}_C$) that preserves document-native layouts and cross-modal alignments through iterative VLM-based message passing. Simultaneously, it employs a Planning Graph ($\mathcal{G}_P$), an agentic DAG that decomposes queries into sub-questions and dynamically refines reasoning paths based on evidence sufficiency. 

![Overview](asset/overview.png)

---

## âœ¨ Highlights
* ğŸ—ï¸ **Dual-Graph Synergy** â€“ Integrates a Content Graph ($\mathcal{G}_C$) for structured evidence representation with a Planning Graph ($\mathcal{G}_P$) for agentic reasoning control.
* ğŸ§¬ **Content Graph Evolution** â€“ Unlike static chunking, $\mathcal{G}_C$ preserves document layouts and cross-modal links through iterative joint evolution, where VLM-based message passing enriches node attributes and induces semantic edges.
* ğŸ§  **Planning Graph Evolution** â€“ $\mathcal{G}_P$ maintains an agentic DAG of sub-questions that dynamically refines its structure based on evidence sufficiency, allowing the system to bridge information gaps through iterative replanning.
  
---

## ğŸš€ Getting Started

### 1. ğŸ› ï¸ Installation

```bash
# Create environment
conda create -n G2-reader python=3.10
conda activate G2-reader

# Clone repository
git clone https://github.com/justLittleWhite/G2-Reader.git
cd G2-Reader

# Install dependencies
pip install -r requirements.txt
```

### 2. âš™ï¸ Configuration

Set up your LLM API and base paths in `config/config.py`:

```python
LLM_BASE_URL = "https://api.openai.com/v1"
LLM_API_KEY = "your-api-key"

# Data root directory
DATA_ROOT = "/path/to/your/data"
```

## ğŸ“ Project Structure

```text
G2-Reader/
â”œâ”€â”€ agent_search/      # Core Logic: DAG decomposition, reasoners, and execution engine
â”œâ”€â”€ prebuild/          # Preprocessing: Documents parsing  and Content Graph construction
â”œâ”€â”€ config/            # Configuration: Model parameters and Prompt templates
â”œâ”€â”€ scripts/           # Execution: End-to-end inference and accuracy evaluation
â”œâ”€â”€ data/              # Dataset: Supports five multimodal domains from VisDoMBench
â””â”€â”€ utils/             # Helpers: Function for Graph operations
```

---

### 3. â±ï¸ Quick Inference

You can run full evaluations or single inference tasks using the provided scripts.

**Run inference:**
```bash
bash scripts/G2reader.sh
```

**Run evaluation:**
```bash
python scripts/evaluate.py
```

---

## ğŸ“¢ News
* [2026-01-28] ğŸ‰ Project cleanup completed and code successfully uploaded to GitHub.
* [2026-01-xx] ğŸ“„ D2-Reader paper submitted.

---

## âœï¸ Citation

If you find D2-Reader useful for your research, please cite:

```bibtex
@article{zhou2026d2reader,
  title={D2-Reader: Dynamic DAG-based Document Reader for Multi-modal Long-Document Understanding},
  author={Yifan Zhou and et al.},
  journal={arXiv preprint arXiv:25xx.xxxxx},
  year={2026}
}
```

---

## ğŸ“ License

This project is licensed under the **Apache 2.0** License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgements
We thank **MinerU** for providing high-quality PDF parsing capabilities, and the open-source community for the foundational models (OpenAI/Qwen) that power this project.
